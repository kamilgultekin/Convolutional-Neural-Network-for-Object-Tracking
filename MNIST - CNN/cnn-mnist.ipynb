{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "colab_type": "code",
    "id": "Rlp5wUW_FDmH",
    "outputId": "375cb352-57f9-4bc4-aa5b-8a9824e8cad2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\envs\\vision-project\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importing the relevant packages\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading and preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before continuing with our model and training, our first job is to preprocess the dataset\n",
    "# This is a very important step in all of machine learning\n",
    "\n",
    "# The MNIST dataset is, in general, highly processed already - after all its 28x28 grayscale images of clearly visible digits\n",
    "# Thus, our preprocessing will be limited to scaling the pixel values, shuffling the data and creating a validation set\n",
    "\n",
    "# NOTE: When finally deploying a model in practice, it might be a good idea to include the prerpocessing as initial layers\n",
    "# In that way, the users could just plug the data (images) directly, instead of being required to resize/rescale it before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Defining some constants/hyperparameters\n",
    "BUFFER_SIZE = 70_000 # for reshuffling\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Downloading the MNIST dataset\n",
    "\n",
    "# When 'with_info' is set to True, tfds.load() returns two variables: \n",
    "# - the dataset (including the train and test sets) \n",
    "# - meta info regarding the dataset itself\n",
    "\n",
    "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Extracting the train and test datasets\n",
    "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Creating a function to scale our image data (it is recommended to scale the pixel values in the range [0,1] )\n",
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255.\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "train_and_validation_data = mnist_train.map(scale)\n",
    "test_data = mnist_test.map(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Defining the size of the validation set\n",
    "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Defining the size of the test set\n",
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Reshuffling the dataset\n",
    "train_and_validation_data = train_and_validation_data.shuffle(BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into training + validation\n",
    "train_data = train_and_validation_data.skip(num_validation_samples)\n",
    "validation_data = train_and_validation_data.take(num_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Batching the data\n",
    "# NOTE: For proper functioning of the model, we need to create one big batch for the validation and test sets\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "validation_data = validation_data.batch(num_validation_samples) \n",
    "test_data = test_data.batch(num_test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model and training it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have preprocessed the dataset, we can define our CNN and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Outlining the model/architecture of our CNN\n",
    "# CONV -> MAXPOOL -> CONV -> MAXPOOL -> FLATTEN -> DENSE\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(50, 5, activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)), \n",
    "    # (2,2) is the default pool size so we could have just used MaxPooling2D() with no explicit arguments\n",
    "    tf.keras.layers.Conv2D(50, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)), \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10) # You can apply softmax activation here, see below for comentary\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "___________________________________________________________________________\n",
      "Layer (type)                     Output Shape                  Param #     \n",
      "===========================================================================\n",
      "conv2d (Conv2D)                  (None, 24, 24, 50)            1300        \n",
      "___________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)     (None, 12, 12, 50)            0           \n",
      "___________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 10, 10, 50)            22550       \n",
      "___________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 5, 5, 50)              0           \n",
      "___________________________________________________________________________\n",
      "flatten (Flatten)                (None, 1250)                  0           \n",
      "___________________________________________________________________________\n",
      "dense (Dense)                    (None, 10)                    12510       \n",
      "===========================================================================\n",
      "Total params: 36,360\n",
      "Trainable params: 36,360\n",
      "Non-trainable params: 0\n",
      "___________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# A brief summary of the model and parameters\n",
    "model.summary(line_length = 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the loss function\n",
    "\n",
    "# In general, our model needs to output probabilities of each class, \n",
    "# which can be achieved with a softmax activation in the last dense layer\n",
    "\n",
    "# However, when using the softmax activation, the loss can rarely be unstable\n",
    "\n",
    "# Thus, instead of incorporating the softmax into the model itself,\n",
    "# we use a loss calculation that automatically corrects for the missing softmax\n",
    "\n",
    "# That is the reason for 'from_logits=True'\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Compiling the model with Adam optimizer and the cathegorical crossentropy as a loss function\n",
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Defining early stopping to prevent overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    mode = 'auto',    \n",
    "    min_delta = 0,\n",
    "    patience = 2,\n",
    "    verbose = 0, \n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "422/422 - 22s - loss: 0.2787 - accuracy: 0.9208 - val_loss: 0.0823 - val_accuracy: 0.9737\n",
      "Epoch 2/20\n",
      "422/422 - 23s - loss: 0.0718 - accuracy: 0.9783 - val_loss: 0.0613 - val_accuracy: 0.9822\n",
      "Epoch 3/20\n",
      "422/422 - 23s - loss: 0.0522 - accuracy: 0.9841 - val_loss: 0.0358 - val_accuracy: 0.9895\n",
      "Epoch 4/20\n",
      "422/422 - 23s - loss: 0.0433 - accuracy: 0.9869 - val_loss: 0.0340 - val_accuracy: 0.9893\n",
      "Epoch 5/20\n",
      "422/422 - 23s - loss: 0.0369 - accuracy: 0.9889 - val_loss: 0.0253 - val_accuracy: 0.9907\n",
      "Epoch 6/20\n",
      "422/422 - 26s - loss: 0.0303 - accuracy: 0.9908 - val_loss: 0.0264 - val_accuracy: 0.9920\n",
      "Epoch 7/20\n",
      "422/422 - 28s - loss: 0.0262 - accuracy: 0.9919 - val_loss: 0.0166 - val_accuracy: 0.9950\n",
      "Epoch 8/20\n",
      "422/422 - 26s - loss: 0.0227 - accuracy: 0.9928 - val_loss: 0.0175 - val_accuracy: 0.9942\n",
      "Epoch 9/20\n",
      "422/422 - 27s - loss: 0.0206 - accuracy: 0.9937 - val_loss: 0.0178 - val_accuracy: 0.9948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2275618ed60>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the network\n",
    "model.fit(\n",
    "    train_data, \n",
    "    epochs = NUM_EPOCHS, \n",
    "    callbacks = [early_stopping], \n",
    "    validation_data = validation_data,\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nFoXl2txFDmV",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 885us/step - loss: 0.0290 - accuracy: 0.9903\n"
     ]
    }
   ],
   "source": [
    "# Testing our model\n",
    "test_loss, test_accuracy = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nFoXl2txFDmV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0290. Test accuracy: 99.03%\n"
     ]
    }
   ],
   "source": [
    "# Printing the test results\n",
    "print('Test loss: {0:.4f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting images and the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the test_data into 2 arrays, containing the images and the corresponding labels\n",
    "for images, labels in test_data.take(1):\n",
    "    images_test = images.numpy()\n",
    "    labels_test = labels.numpy()\n",
    "\n",
    "# Reshape the images into 28x28 form, suitable for matplotlib (original dimensions: 28x28x1)\n",
    "images_plot = np.reshape(images_test, (10000,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAH4AAAB7CAYAAACy7jQ7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAD/0lEQVR4nO2dzSstcRyH77koTnnJygKrs5KUJEWksJDsRPEPeCn5FxQrWUmytxE2koUSJWEhZYWVLCyQl1Lyeu7mLu7nO93fuefOyPx8Ps/u6Zw551dP0/fMjBmJdDr9Q/Dx86sXIL4GhSdF4UlReFIUnhSFJyXX9WIikdCxnsek0+nE317THk+KwpOi8KQoPCkKT4rCk6LwpCg8KQpPisKTovCkKDwpCk+KwpOi8KQoPCkKT4rCk6LwpCg8KQpPisKTovCkKDwpCk+KwpOi8KQoPCkKT4rCk+K8TVpES0FBAXhbW5vz/U9PT+Cbm5uRrUV7PCkKT4rCk+LVjM/JyQGfmJgA7+vrc25vZ6Td/uLiAjzTUz/teqyPj4+D9/f3g5eXlzs//+3tDXxvbw+8t7cX/Orqyvl5f6I9nhSFJ0XhSUm45thXP+6ssLAQfGlpCbyjoyPS7xsdHQU/OTkB7+npAa+vrwevra2NdD3ZYn9j6HFnIoDCk6LwpMRqxldUVICvra2BV1dXO7e/vLwEHxoaAm9oaAAfHBwELy0t/ad1RsXBwQH49PQ0+O3tbVaft7W1Ba4ZLwIoPCkKT0qsZvzGxgZ4puvVdqZ3dXWBHx8fO7ff2dkBb2xszLREJ8/Pz+ALCwvgk5OT4Pbcur3+HhbNeBFA4UlReFJidT2+vb0d3P7+eH9/d77/9PT0cxb2m7u7O/DFxUXwqakp8PPz809dTxi0x5Oi8KTE6nDOruXj4wP89fUVPD8/P9T31dTUgI+NjYE/PDyAz83NgZ+dnYX6/s9Gh3MigMKTovCkxGrGz8zMgA8PDzvfPzIyAm5PkT4+PkazME/RjBcBFJ4UhSclVjO+qKgIfHl5GTzTZdrt7W3wzs5O8JeXl/9fnIdoxosACk+KwpMSqxlvKSkpAV9ZWQFvbW11br+/vw/e1NQUybp8QTNeBFB4UhSelFjPeEsymQRfX18Hb25udm4/Pz8Pbq+/f7fjfM14EUDhSVF4Urya8Zbi4mJw+6iUTOf2W1pawHd3d6NZWEzQjBcBFJ4UhSfF6xlvqaurA7fX5+15gNnZWXD7uDPf0YwXARSeFIUnJVa3SYfl8PAQ/P7+HtzO+MrKSnD7SFB7W/Z3Qns8KQpPisKT4tWMz83F5dr71e0jQjM9orS7u9v5/uvr62yX6A3a40lReFIUnhSvztXbGX90dAReVVUV6vPLysrAfZ/xOlcvAig8KV4dztn/vGj/tGpgYAA8Ly8PPJVKga+uroLf3NyEXaI3aI8nReFJUXhSvDqcE9mhwzkRQOFJUXhSFJ4UhSdF4UlReFIUnhSFJ0XhSVF4Upzn6sX3RXs8KQpPisKTovCkKDwpCk/KL7SLIw66TKMCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n"
     ]
    }
   ],
   "source": [
    "# The image to be displayed and tested\n",
    "i = 502\n",
    "\n",
    "\n",
    "# Plot the image\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.axis('off')\n",
    "plt.imshow(images_plot[i-1], cmap=\"gray\", aspect='auto')\n",
    "plt.show()\n",
    "\n",
    "# Print the correct label for the image\n",
    "print(\"Label: {}\".format(labels_test[i-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAAEvCAYAAABGywdiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAQxklEQVR4nO3dccjtd33Y8fenuXaaODE2NyE1btdCcHXCplycrSBlqZtWMdlAiGAJRcgYrtNuUGL/kf1RsFBK98dWCMb2jjolixalFWtI67r+UdubaNEYXZzaGE2T23WttRvVtN/98ZyNW7mSes9znnO9z+sFl3PO75zznM+PJ/e57/ye7zm/WWsFAADH3XftewAAALgUCGMAAEgYAwBAJYwBAKASxgAAUAljAACo6sS+B6i65ppr1qlTp/Y9BgAAl7n777//j9ZaJy903yURxqdOners2bP7HgMAgMvczPzBt7rvKZdSzMy7ZuaJmfnUedueMzP3zszDm8urz7vvbTPzuZn57Mz80+3HBwCA3fubrDH+pepV37Ttjuq+tdaN1X2b283MC6tbq7+/ec5/nJkrDm1aAADYkacM47XWb1V//E2bb67ObK6fqW45b/t711p/sdb6QvW56qWHNCsAAOzMxX4qxXVrrceqNpfXbrY/t/rSeY97dLMNAAAuaYf9cW1zgW3rgg+cuX1mzs7M2XPnzh3yGAAA8O252DB+fGaur9pcPrHZ/mj1vPMed0P1lQt9gbXWnWut02ut0ydPXvATMwAA4MhcbBh/sLptc/226gPnbb91Zv7WzDy/urH63e1GBACA3XvKzzGemfdUP1RdMzOPVm+v3lHdPTNvqh6pXl+11npwZu6uPl09Wb15rfWXO5odAAAOzVOG8VrrDd/irpu+xeN/uvrpbYYCAICjdthvvgMAgO9IwhgAAPobLKUAALgUnbrj1/Y9wta++I7X7HsEzuOIMQAAJIwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAtWUYz8xPzMyDM/OpmXnPzDx9Zp4zM/fOzMOby6sPa1gAANiViw7jmXlu9a+r02utF1VXVLdWd1T3rbVurO7b3AYAgEvatkspTlTPmJkT1ZXVV6qbqzOb+89Ut2z5GgAAsHMXHcZrrS9XP1s9Uj1W/ela6yPVdWutxzaPeay69jAGBQCAXdpmKcXVHRwdfn71vdVVM/PGb+P5t8/M2Zk5e+7cuYsdAwAADsU2Syl+uPrCWuvcWusb1furH6wen5nrqzaXT1zoyWutO9dap9dap0+ePLnFGAAAsL1twviR6mUzc+XMTHVT9VD1weq2zWNuqz6w3YgAALB7Jy72iWutj83MPdUD1ZPVx6s7q2dWd8/MmzqI59cfxqAAALBLFx3GVWutt1dv/6bNf9HB0WMAAPiO4cx3AACQMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKDaMoxn5tkzc8/MfGZmHpqZH5iZ58zMvTPz8Oby6sMaFgAAdmXbI8b/vvrwWuvvVf+geqi6o7pvrXVjdd/mNgAAXNIuOoxn5lnVK6q7qtZaX19r/Ul1c3Vm87Az1S3bDgkAALu2zRHj76vOVb84Mx+fmXfOzFXVdWutx6o2l9cewpwAALBT24Txieol1S+stV5c/XnfxrKJmbl9Zs7OzNlz585tMQYAAGxvmzB+tHp0rfWxze17Ogjlx2fm+qrN5RMXevJa68611um11umTJ09uMQYAAGzvosN4rfWH1Zdm5gWbTTdVn64+WN222XZb9YGtJgQAgCNwYsvn/3j17pn57urz1Y91ENt3z8ybqkeq12/5GgAAsHNbhfFa6xPV6QvcddM2XxcAAI6aM98BAEDCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAdQhhPDNXzMzHZ+ZXN7efMzP3zszDm8urtx8TAAB26zCOGL+leui823dU9621bqzu29wGAIBL2lZhPDM3VK+p3nne5purM5vrZ6pbtnkNAAA4CtseMf756iervzpv23VrrceqNpfXXuiJM3P7zJydmbPnzp3bcgwAANjORYfxzLy2emKtdf/FPH+tdeda6/Ra6/TJkycvdgwAADgUJ7Z47sur183Mj1RPr541M79cPT4z16+1HpuZ66snDmNQAADYpYs+YrzWetta64a11qnq1uo31lpvrD5Y3bZ52G3VB7aeEgAAdmwXn2P8juqVM/Nw9crNbQAAuKRts5Ti/1trfbT66Ob6/6xuOoyvCwAAR8WZ7wAAIGEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAtUUYz8zzZuY3Z+ahmXlwZt6y2f6cmbl3Zh7eXF59eOMCAMBubHPE+Mnq3661vr96WfXmmXlhdUd131rrxuq+zW0AALikXXQYr7UeW2s9sLn+Z9VD1XOrm6szm4edqW7ZdkgAANi1Q1ljPDOnqhdXH6uuW2s9VgfxXF17GK8BAAC7tHUYz8wzq/dVb11rffXbeN7tM3N2Zs6eO3du2zEAAGArW4XxzDytgyh+91rr/ZvNj8/M9Zv7r6+euNBz11p3rrVOr7VOnzx5cpsxAABga9t8KsVUd1UPrbV+7ry7Pljdtrl+W/WBix8PAACOxoktnvvy6kerT87MJzbbfqp6R3X3zLypeqR6/XYjAgDA7l10GK+1fruab3H3TRf7dQEAYB+c+Q4AABLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoKoT+x4AgMN16o5f2/cIh+KL73jNvkcAjhlHjAEAIGEMAADVDsN4Zl41M5+dmc/NzB27eh0AADgMOwnjmbmi+g/Vq6sXVm+YmRfu4rUAAOAw7OqI8Uurz621Pr/W+nr13urmHb0WAABsbVdh/NzqS+fdfnSzDQAALkm7+ri2ucC29dceMHN7dfvm5tdm5rM7muVScE31R/seYg/s9/Fiv4+Xne/3/Mwuv/pF8/0+fna675fof+d1eX/P/+63umNXYfxo9bzzbt9QfeX8B6y17qzu3NHrX1Jm5uxa6/S+5zhq9vt4sd/Hi/0+Xo7rftfx3ffjut+7Wkrxe9WNM/P8mfnu6tbqgzt6LQAA2NpOjhivtZ6cmX9V/Xp1RfWutdaDu3gtAAA4DDs7JfRa60PVh3b19b/DHIslIxdgv48X+3282O/j5bjudx3ffT+W+z1rrad+FAAAXOacEhoAABLGO3VcT4s9M++amSdm5lP7nuWozMzzZuY3Z+ahmXlwZt6y75mOwsw8fWZ+d2Z+f7Pf/27fMx2lmbliZj4+M7+671mO0sx8cWY+OTOfmJmz+57nqMzMs2fmnpn5zObv+g/se6Zdm5kXbL7P/+/PV2fmrfue6yjMzE9sfq59ambeMzNP3/dMR2Fm3rLZ5wePy/f6fJZS7MjmtNj/vXplBx9f93vVG9Zan97rYEdgZl5Rfa36T2utF+17nqMwM9dX16+1HpiZv13dX91yuX+/Z2aqq9ZaX5uZp1W/Xb1lrfU7ex7tSMzMv6lOV89aa7123/MclZn5YnV6rXW5fsbpBc3Mmeq/rbXeufnEpSvXWn+y77mOyubftS9X/2it9Qf7nmeXZua5Hfw8e+Fa6//MzN3Vh9Zav7TfyXZrZl7UwdmKX1p9vfpw9S/XWg/vdbAj5Ijx7hzb02KvtX6r+uN9z3GU1lqPrbUe2Fz/s+qhjsHZHteBr21uPm3z51j83/bM3FC9pnrnvmdh92bmWdUrqruq1lpfP05RvHFT9T8u9yg+z4nqGTNzorqybzofw2Xq+6vfWWv977XWk9V/rf7Znmc6UsJ4d5wW+5iamVPVi6uP7XeSo7FZTvCJ6onq3rXWsdjv6uern6z+at+D7MGqPjIz92/OYnocfF91rvrFzfKZd87MVfse6ojdWr1n30MchbXWl6ufrR6pHqv+dK31kf1OdSQ+Vb1iZr5nZq6sfqS/fsK2y54w3p2nPC02l5+ZeWb1vuqta62v7nueo7DW+su11j/s4AyXL938Ku6yNjOvrZ5Ya92/71n25OVrrZdUr67evFk+dbk7Ub2k+oW11ourP6+O03tHvrt6XfVf9j3LUZiZqzv4Le/zq++trpqZN+53qt1baz1U/Ux1bwfLKH6/enKvQx0xYbw7T3labC4vmzW276vevdZ6/77nOWqbXyt/tHrVnkc5Ci+vXrdZa/ve6h/PzC/vd6Sjs9b6yubyiepXOlg6drl7tHr0vN+I3NNBKB8Xr64eWGs9vu9BjsgPV19Ya51ba32jen/1g3ue6Uiste5aa71krfWKDpZFHpv1xSWMd8lpsY+RzZvQ7qoeWmv93L7nOSozc3Jmnr25/owO/jH5zH6n2r211tvWWjestU518Hf7N9Zal/3RpKqZuWrzBtM2Swn+SQe/fr2srbX+sPrSzLxgs+mm6rJ+c+03eUPHZBnFxiPVy2bmys3P95s6eO/IZW9mrt1c/p3qn3e8vu+7O/PdcXecT4s9M++pfqi6ZmYerd6+1rprv1Pt3MurH60+uVlvW/VTmzNAXs6ur85s3q3+XdXda61j9dFlx9B11a8ctEInqv+81vrwfkc6Mj9evXtzsOPz1Y/teZ4jsVlr+srqX+x7lqOy1vrYzNxTPdDBUoKPd3zOBPe+mfme6hvVm9da/2vfAx0lH9cGAABZSgEAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAACq+r+bp5lLKiwu1AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtain the model's predictions (logits)\n",
    "predictions = model.predict(images_test[i-1:i])\n",
    "\n",
    "# Convert those predictions into probabilities (recall that we incorporated the softmaxt activation into the loss function)\n",
    "probabilities = tf.nn.softmax(predictions).numpy()\n",
    "# Convert the probabilities into percentages\n",
    "probabilities = probabilities*100\n",
    "\n",
    "\n",
    "# Create a bar chart to plot the probabilities for each class\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.bar(x=[1,2,3,4,5,6,7,8,9,10], height=probabilities[0], tick_label=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "defaultNotebook.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
